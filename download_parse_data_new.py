import pandas as pd
import psycopg2
import os
import re
import gzip
import subprocess
import shutil
import urllib.request
import json
import requests
import gzip    
import subprocess
import shutil
from datetime import datetime
from typing import Dict, List, Optional

# --- Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ ---
CLINVAR_VARIANT_URL = "https://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/variant_summary.txt.gz"
CLINVAR_SUBMISSION_URL = "https://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/submission_summary.txt.gz" #Î¼Î¿ÏÏ†Î® gzip
GENE_FILTER = "KLHL10"
ASSEMBLY_FILTER = "GRCh38"  #Î•Ï€Î¹Î»Î­Î³ÎµÎ¹ Ï„Î·Î½ Î­ÎºÎ´Î¿ÏƒÎ· GRCh38 Ï„Î¿Ï… Î³Î¿Î½Î¹Î´Î¹ÏÎ¼Î±Ï„Î¿Ï‚
CLINVAR_SUBMISSION_URL = "https://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/submission_summary.txt.gz"
TRUSTED_SUBMITTERS = {'ClinVar', 'ENIGMA'}

#Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ Î’Î¬ÏƒÎ·Ï‚ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
DB_CONFIG = {
    "dbname": "clinvar_db",
    "user": "ilianam",
    "password": "genekor123!",
    "host": "localhost",
    "port": 5432
}

#Î’Î¿Î·Î¸Î·Ï„Î¹ÎºÎ­Ï‚ Î£Ï…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚


def get_header_from_commented_tsv(gz_path: str) -> list:
    """
    Î•Î½Ï„Î¿Ï€Î¯Î¶ÎµÎ¹ Ï„Î· Î³ÏÎ±Î¼Î¼Î® header Ï€Î¿Ï… Î¾ÎµÎºÎ¹Î½Î¬ÎµÎ¹ Î¼Îµ # ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„Î± Î¿Î½ÏŒÎ¼Î±Ï„Î± ÏƒÏ„Î·Î»ÏÎ½ Ï‰Ï‚ Î»Î¯ÏƒÏ„Î±.
    """
    with gzip.open(gz_path, 'rt') as f:
        for line in f:
            if line.startswith('#') and 'VariationID' in line:
                return line.lstrip('#').strip().split('\t')
    raise ValueError("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î³ÏÎ±Î¼Î¼Î® ÎºÎµÏ†Î±Î»Î¯Î´Î±Ï‚ Î¼Îµ 'VariationID'")

def merge_variant_submission(variant_path: str, submission_path: str) -> pd.DataFrame:
        """
        Î£Ï…Î½Î´Ï…Î¬Î¶ÎµÎ¹ variant_summary ÎºÎ±Î¹ Î¼ÏŒÎ½Î¿ Ï„Î¿Ï…Ï‚ Submitter Î±Ï€ÏŒ submission_summary Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ VariationID.
        """

        print("Î¦ÏŒÏÏ„Ï‰ÏƒÎ· variant_summary...")
        df_variant = pd.read_csv(variant_path, sep='\t', low_memory=False)

        # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± variant_summary
        df_variant = df_variant[
            (df_variant['GeneSymbol'] == GENE_FILTER) &
            (df_variant['Assembly'] == ASSEMBLY_FILTER)
        ].copy()

        print(f"ÎœÎµÏ„Î¬ Ï„Î¿ Ï†Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î±: {len(df_variant)} ÎµÎ³Î³ÏÎ±Ï†Î­Ï‚")

        # Î•Î¾Î±Î³Ï‰Î³Î® unique VariationIDs
        variation_ids = set(df_variant['VariationID'].dropna().unique())

        print("Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ Ï†Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± submission_summary...")
        submitters_dict = {}

        print("Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ Ï†Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± submission_summary...")

        # â¤ Î Î¬ÏÎµ Ï„Î¿ ÏƒÏ‰ÏƒÏ„ÏŒ header Î±Ï€ÏŒ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ gzip
        header_line = get_header_from_commented_tsv(submission_path)
        print("ğŸ” Header columns:", header_line)


        # â¤ Î‘Î½Î¬Î³Î½Ï‰ÏƒÎ· Î¼Îµ Ï„Î¿ ÏƒÏ‰ÏƒÏ„ÏŒ header
        submitters_dict = {}
        for chunk in pd.read_csv(
            submission_path,
            sep='\t',
            comment='#',
            names=header_line,
            compression='gzip',
            usecols=['VariationID', 'Submitter'],
            chunksize=500_000
        ):
            filtered = chunk[chunk['VariationID'].isin(variation_ids)]
            for _, row in filtered.iterrows():
                vid = row['VariationID']
                sub = row['Submitter']
                if pd.notna(sub):
                    submitters_dict.setdefault(vid, set()).add(sub)

        # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ DataFrame
        df_submitters = pd.DataFrame([
            {'VariationID': vid, 'Submitter': sorted(list(subs))}
            for vid, subs in submitters_dict.items()
        ])

        print(f"âœ“ Î’ÏÎ­Î¸Î·ÎºÎ±Î½ submitters Î³Î¹Î± {len(df_submitters)} VariationIDs")

        # Î£Ï…Î³Ï‡ÏÎ½ÎµÏ…ÏƒÎ·
        merged_df = pd.merge(
            df_variant,
            df_submitters,
            how='left',
            on='VariationID'
        )

        # Î‘Î½ Î¸Î­Î»ÎµÎ¹Ï‚ pipe-separated string Î±Î½Ï„Î¯ Î³Î¹Î± Î»Î¯ÏƒÏ„Î±:
        merged_df['Submitter'] = merged_df['Submitter'].apply(
            lambda x: '|'.join(x) if isinstance(x, list) else None
        )

        print(f"âœ“ Î£Ï…Î³Ï‡Ï‰Î½ÎµÏÎ¸Î·ÎºÎ±Î½: {merged_df['Submitter'].notna().sum()}/{len(merged_df)} Î¼Îµ Submitter")

        return merged_df



#grep h zcat gia na mh skaei
def create_tables(conn: psycopg2.extensions.connection) -> None:
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï€Î¹Î½Î¬ÎºÏ‰Î½ ÏƒÏ„Î· Î²Î¬ÏƒÎ·"""
    with conn.cursor() as cur:
        # ÎšÏÏÎ¹Î¿Ï‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚ Î¼ÎµÏ„Î±Î»Î»Î¬Î¾ÎµÏ‰Î½
        cur.execute("""
        CREATE TABLE IF NOT EXISTS brca1_variants (
            variation_id BIGINT PRIMARY KEY,
            gene_symbol TEXT NOT NULL,
            transcript_id TEXT,
            variant_type TEXT,
            hgvs_c TEXT,
            hgvs_p TEXT,
            clinical_significance TEXT,
            review_status TEXT,
            phenotype_list TEXT,
            assembly TEXT NOT NULL,
            chromosome TEXT,
            start_pos INTEGER,
            end_pos INTEGER,
            reference_allele TEXT,
            alternate_allele TEXT,
            acmg_criteria JSONB,
            conflicting_interpretations JSONB,
            rcv_accessions TEXT[],
            last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            last_evaluated DATE
        );
        """)
        conn.commit()

#ACMG Criteria
def apply_acmg_criteria(row: pd.Series) -> List[str]:
    """Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎºÏÎ¹Ï„Î·ÏÎ¯Ï‰Î½ ACMG Î³Î¹Î± Î¼Î¹Î± Î¼ÎµÏ„Î¬Î»Î»Î±Î¾Î·"""
    criteria = []
    
    # Î“Î½Ï‰ÏƒÏ„Î­Ï‚ pathogenic Î¼ÎµÏ„Î±Î»Î»Î¬Î¾ÎµÎ¹Ï‚ (Ï€ÏÎ¿ÏƒÎ±ÏÎ¼ÏŒÏƒÏ„Îµ Î±Î½Î¬Î»Î¿Î³Î±)
    known_pathogenic = {
        'p.Arg504Gly': {'dna': 'c.1510A>T', 'significance': 'Pathogenic'},
        'p.Trp41*': {'dna': 'c.123G>A', 'significance': 'Pathogenic'}
    }

    # Î‘Î¾Î¹ÏŒÏ€Î¹ÏƒÏ„Î¿Î¹ Ï…Ï€Î¿Î²Î¬Î»Î»Î¿Î½Ï„ÎµÏ‚
    trusted_submitters = {'ClinVar', 'ExpertLab'}
    
    # Î˜Î­ÏƒÎµÎ¹Ï‚ Î¼Îµ Î³Î½Ï‰ÏƒÏ„Î­Ï‚ Ï€Î±Î¸Î¿Î³Î¿Î½Î¹ÎºÎ­Ï‚ Î¼ÎµÏ„Î±Î»Î»Î¬Î¾ÎµÎ¹Ï‚ (Ï€.Ï‡. 41, 504)
    pathogenic_positions = {41, 504}

    # PS1: ÎŠÎ´Î¹Î¿ protein change, Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÏŒ DNA change
    if row['HGVS_p'] in known_pathogenic:
        if row['HGVS_c'] != known_pathogenic[row['HGVS_p']]['dna']:
            criteria.append("PS1")
    
        # PM5
    protein_pos = int(''.join(filter(str.isdigit, row['HGVS_p']))) if pd.notna(row['HGVS_p']) else None
    if protein_pos in pathogenic_positions and row['HGVS_p'] not in known_pathogenic:
        criteria.append('PM5')
    
    # PP5/BP6

    submitter = row.get('Submitter', None)
    if submitter in trusted_submitters:
        if row['ClinicalSignificance'] == 'Pathogenic':
            criteria.append('PP5')
        elif row['ClinicalSignificance'] == 'Benign':
            criteria.append('BP6')

        '''
    if row['Submitter'] in trusted_submitters:
        if row['ClinicalSignificance'] == 'Pathogenic':
            criteria.append('PP5')
        elif row['ClinicalSignificance'] == 'Benign':
            criteria.append('BP6')
'''
    return criteria


    
    # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Ï„Î¿Ï… Î²Î±Î¸Î¼Î¿Ï ÏƒÏÎ³ÎºÎ»Î¹ÏƒÎ·Ï‚/Î´Î¹Î±Ï†Ï‰Î½Î¯Î±Ï‚
    def calculate_conflict_score(conflict_data):
        if not conflict_data or len(conflict_data['interpretations']) <= 1:
            return 0
        total = sum(conflict_data['interpretations'].values())
        max_agree = max(conflict_data['interpretations'].values())
        return 1 - (max_agree / total)
    
    df_brca['conflict_score'] = (
        df_brca['conflicting_interpretations']
        .apply(calculate_conflict_score)
    )
    
    # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÏƒÏ„Î®Î»Î·Ï‚ Ï€Î¿Ï… Î´ÎµÎ¯Ï‡Î½ÎµÎ¹ Î±Î½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ conflicting interpretations
    df_brca['has_conflicts'] = (
        df_brca['conflict_score'] > 0.2
    )  # ÎŸÏÎ¯Î¶Î¿Ï…Î¼Îµ threshold 20% Î´Î¹Î±Ï†Ï‰Î½Î¯Î±
    
    # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ACMG criteria
    df_brca['acmg_criteria'] = df_brca.apply(apply_acmg_criteria, axis=1)
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î»Î¯ÏƒÏ„Î±Ï‚ RCV accessions
    df_brca['rcv_accessions'] = df_brca['RCVaccession'].str.split('|')
    
    return df_brca

#Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® ÏƒÏ„Î· Î’Î¬ÏƒÎ·
def insert_to_database(conn: psycopg2.extensions.connection, df: pd.DataFrame) -> None:
    """Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÏƒÏ„Î· Î²Î¬ÏƒÎ·"""
    with conn.cursor() as cur:
        for _, row in df.iterrows():
            cur.execute("""
            INSERT INTO brca1_variants (
                variation_id, gene_symbol, transcript_id, hgvs_c, hgvs_p, variant_type,
                clinical_significance, review_status, phenotype_list,
                assembly, chromosome, start_pos, end_pos,
                reference_allele, alternate_allele, acmg_criteria,
                conflicting_interpretations, rcv_accessions
            ) VALUES (
                %s, %s, %s, %s, %s, %s,
                %s, %s, %s,
                %s, %s, %s, %s,
                %s, %s, %s,
                %s, %s
            )
            ON CONFLICT (variation_id) DO UPDATE SET
                gene_symbol = EXCLUDED.gene_symbol,
                transcript_id = EXCLUDED.transcript_id,
                hgvs_c = EXCLUDED.hgvs_c,
                hgvs_p = EXCLUDED.hgvs_p,
                variant_type = EXCLUDED.variant_type,
                clinical_significance = EXCLUDED.clinical_significance,
                review_status = EXCLUDED.review_status,
                phenotype_list = EXCLUDED.phenotype_list,
                assembly = EXCLUDED.assembly,
                chromosome = EXCLUDED.chromosome,
                start_pos = EXCLUDED.start_pos,
                end_pos = EXCLUDED.end_pos,
                reference_allele = EXCLUDED.reference_allele,
                alternate_allele = EXCLUDED.alternate_allele,
                acmg_criteria = EXCLUDED.acmg_criteria,
                conflicting_interpretations = EXCLUDED.conflicting_interpretations,
                rcv_accessions = EXCLUDED.rcv_accessions,
                last_updated = CURRENT_TIMESTAMP;
            """, (
                row['VariationID'], row['GeneSymbol'], row['transcript_id'], row['HGVS_c'], row['HGVS_p'], row['variant_type'],
                row['ClinicalSignificance'], row['ReviewStatus'], row['PhenotypeList'],
                row['Assembly'], row['Chromosome'], row['Start'], row['Stop'],
                row['ReferenceAllele'], row['AlternateAllele'], json.dumps(row['acmg_criteria']),
                json.dumps(row['conflicting_interpretations']), row['rcv_accessions']
            ))
        conn.commit()

   
def extract_HGVS(name: str) -> dict:
    """
    Î•Î¾Î¬Î³ÎµÎ¹ HGVS.c, HGVS.p ÎºÎ±Î¹ variant_type Î±Ï€ÏŒ Ï„Î¿ Ï€ÎµÎ´Î¯Î¿ name Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ regex patterns.
    """
    result = {
        'HGVS_c': None,
        'HGVS_p': None,
        'variant_type': None,
        'Other_variant': None
    }
    
    if not pd.isna(name) and isinstance(name, str):
        dna_pattern = re.compile(r'(c\.[^*\s]+)')  # DNA Î¼ÎµÏ„Î±Î»Î»Î¬Î¾ÎµÎ¹Ï‚ (c.) Ï‡Ï‰ÏÎ¯Ï‚ *
        dna_star_pattern = re.compile(r'(c\.\*[\d_]+[^\s)]*)')  # DNA Î¼ÎµÏ„Î±Î»Î»Î¬Î¾ÎµÎ¹Ï‚ Î¼Îµ * (Ï€.Ï‡. c.*103_*106del)
        protein_pattern = re.compile(r'(p\.[^\s)]+)')  # Î ÏÏ‰Ï„ÎµÏŠÎ½Î¹ÎºÎ­Ï‚ Î¼ÎµÏ„Î±Î»Î»Î¬Î¾ÎµÎ¹Ï‚ (p.)
        
        # Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î³Î¹Î± DNA Î¼ÎµÏ„Î±Î»Î»Î¬Î¾ÎµÎ¹Ï‚
        dna_match = dna_pattern.search(name)
        dna_star_match = dna_star_pattern.search(name)
        
        if dna_match:
            result['HGVS_c'] = dna_match.group(1)
            result['variant_type'] = 'DNA'
        elif dna_star_match:
            result['HGVS_c'] = dna_star_match.group(1)
            result['variant_type'] = 'DNA'
        
        # Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î³Î¹Î± Ï€ÏÏ‰Ï„ÎµÏŠÎ½Î¹ÎºÎ­Ï‚ Î¼ÎµÏ„Î±Î»Î»Î¬Î¾ÎµÎ¹Ï‚
        protein_match = protein_pattern.search(name)
        if protein_match:
            result['HGVS_p'] = protein_match.group(1)
            # Î‘Î½ Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ Î®Î´Î· variant_type DNA, Î²Î¬Î»Îµ protein
            if result['variant_type'] is None:
                result['variant_type'] = 'Protein'
        
        # Î‘Î½ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î¿ÏÏ„Îµ DNA Î¿ÏÏ„Îµ Protein
        if result['variant_type'] is None:
            result['variant_type'] = 'Other'
            result['Other_variant'] = name

    return result

# Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± DataFrame (Î²Î¬Î»Îµ Ï„Î¿ Î´Î¹ÎºÏŒ ÏƒÎ¿Ï…)
df = pd.DataFrame({
    'Name': [
        'c.123A>T',
        'p.Arg117His',
        'c.*103_*106del',
        'p.Gly12Asp c.35G>A',
        'unknown_variant',
        None
    ]
})

# Î•Ï†Î±ÏÎ¼Î¿Î³Î® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·Ï‚ ÎºÎ±Î¹ Ï€ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÏƒÏ„Î·Î»ÏÎ½
df_HGVS = df['Name'].apply(extract_HGVS).apply(pd.Series)
df = pd.concat([df, df_HGVS], axis=1)

print(df)




def process_clinvar_data(variant_gz_path: str) -> pd.DataFrame:
    """
    Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ClinVar Î±Ï€ÏŒ .gz Î¼Îµ zcat ÎºÎ±Î¹ grep (Î³Î¹Î± Ï‡Î±Î¼Î·Î»Î® Ï‡ÏÎ®ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚).
    Î”Î¹Î±Ï„Î·ÏÎµÎ¯ Ï„Î· Î³ÏÎ±Î¼Î¼Î® Ï„Î¯Ï„Î»Ï‰Î½ (header).
    """


    print("Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î¼Îµ zcat + grep...")
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿ Î¼Îµ header + filtered rows
    grep_cmd = (
        f"zcat {variant_gz_path} | head -n 1 > filtered_variants.tsv && "
        f"zcat {variant_gz_path} | grep -E 'KLHL10.*GRCh38' >> filtered_variants.tsv"
    )
    subprocess.run(grep_cmd, shell=True, check=True)

    print("Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Ï†Î¹Î»Ï„ÏÎ±ÏÎ¹ÏƒÎ¼Î­Î½Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½...")
    df = pd.read_csv("filtered_variants.tsv", sep='\t', low_memory=False)

    print("ÎšÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼ÎµÏ„Î±Î»Î»Î¬Î¾ÎµÏ‰Î½...")
    '''
    df['VariantName_analysis'] = df['Name'].apply(extract_HGVS)
    df[['HGVS_c', 'HGVS_p']] = df['VariantName_analysis'].apply(pd.Series)
    if 'HGVS_p' not in df.columns or 'HGVS_c' not in df.columns:
        raise ValueError("Î›ÎµÎ¯Ï€Î¿Ï…Î½ Î¿Î¹ ÏƒÏ„Î®Î»ÎµÏ‚ HGVS_p Î® HGVS_c Ï€ÏÎ¹Î½ Ï„Î¿ determine_variant_type.")

    df['transcript_id'] = df['Name'].apply(extract_transcript_id)
    df['variant_type'] = df.apply(lambda row: determine_variant_type(row['HGVS_p'], row['HGVS_c']), axis=1)
    df['HGVS_c'] = df['VariantName_analysis'].apply(lambda x: x['HGVS_c'])
    df['PHGVS_p'] = df['VariantName_analysis'].apply(lambda x: x['HGVS_p'])
    df['Other_variant'] = df['VariantName_analysis'].apply(lambda x: x['Other_variant'])

    df.drop(columns=['VariantName_analysis'], inplace=True)

    # Î”Î¹Î±Î³ÏÎ±Ï†Î® Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¿Ï Î±ÏÏ‡ÎµÎ¯Î¿Ï…
    os.remove("filtered_variants.tsv")
'''
    # Î•Î¾Î±Î³Ï‰Î³Î® HGVS_c, HGVS_p, variant_type, Other_variant ÏƒÎµ Î¼Î¯Î± Î³ÏÎ±Î¼Î¼Î®
    df = pd.concat([df, df['Name'].apply(extract_HGVS).apply(pd.Series)], axis=1)

    # Î•Î¾Î±Î³Ï‰Î³Î® transcript ID
    df['transcript_id'] = df['Name'].apply(extract_transcript_id)

    # Î”Î¹Î±Î³ÏÎ±Ï†Î® Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¿Ï Î±ÏÏ‡ÎµÎ¯Î¿Ï…
    os.remove("filtered_variants.tsv")
    return df

def extract_transcript_id(name: str)->str:
    if pd.isna(name) or not isinstance(name,str):
        return None
    
    transcript_pattern=re.compile(r'(?<!\w)(NM_\d{5,}(?:\.\d{1,2})?)(?=[(])')

    match = transcript_pattern.search(name)
    
    return match.group(1) if match else None

    '''
    (?<!\w) - Negative lookbehind: Î’ÎµÎ²Î±Î¹ÏÎ½ÎµÏ„Î±Î¹ ÏŒÏ„Î¹ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ word character Ï€ÏÎ¹Î½

([NXY]M_\d{5,}(?:\.\d{1,2})?) - ÎšÏÏÎ¹Î± Î¿Î¼Î¬Î´Î±:

(?<!\w) Negative lookbehind: Î’ÎµÎ²Î±Î¹ÏÎ½ÎµÏ„Î±Î¹ ÏŒÏ„Î¹ Ï„Î¿ NM_ Î´ÎµÎ½ Ï€ÏÎ¿Î·Î³ÎµÎ¯Ï„Î±Î¹ Î±Ï€ÏŒ Î¬Î»Î»Î¿ word character (Ï€.Ï‡. Î³ÏÎ¬Î¼Î¼Î±, Î±ÏÎ¹Î¸Î¼ÏŒ Î® _).

NM_ - Î¤Î±Î¹ÏÎ¹Î¬Î¶ÎµÎ¹ Î±ÎºÏÎ¹Î²ÏÏ‚ Ï„Î¿ Ï€ÏÏŒÎ¸ÎµÎ¼Î± Ï„Ï‰Î½ RefSeq mRNA transcripts.

\d{5,} - Î¤Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ 5 ÏˆÎ·Ï†Î¯Î± (Î¿Î¹ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ¿Î¯ Î±ÏÎ¹Î¸Î¼Î¿Î¯ transcript ÎµÎ¯Î½Î±Î¹ ÏƒÏ…Î½Î®Î¸Ï‰Ï‚ 5-6 ÏˆÎ·Ï†Î¯Î±)

(?:\.\d{1,2})? - Î ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ® Î­ÎºÎ´Î¿ÏƒÎ· (1-2 ÏˆÎ·Ï†Î¯Î±)

(?=[(]) - Positive lookahead: Î ÏÎ­Ï€ÎµÎ¹ Î½Î± Î±ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯Ï„Î±Î¹ Î±Ï€ÏŒ (
'''

def determine_variant_type(hgvs_p: str, hgvs_c: str) -> str:
    """
    ÎšÎ±Î¸Î¿ÏÎ¯Î¶ÎµÎ¹ Ï„Î¿Î½ Ï„ÏÏ€Î¿ Ï„Î·Ï‚ Î¼ÎµÏ„Î¬Î»Î»Î±Î¾Î·Ï‚ Î²Î¬ÏƒÎµÎ¹ Ï„Ï‰Î½ HGVS Ï€ÏÎ¿ÏƒÎ´Î¹Î¿ÏÎ¹ÏƒÎ¼ÏÎ½.
    Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î­Î½Î± Î±Ï€ÏŒ:
    - frameshift, nonsense, deletion, duplication, insertion,
    - missense, synonymous, protein_other,
    - splice_site_essential, splice_region, 5'UTR, 3'UTR, non_coding
    - unknown
    """
    if pd.notna(hgvs_p) and isinstance(hgvs_p, str):
        hgvs_p = hgvs_p.strip()
        if "fs" in hgvs_p:
            return "frameshift"
        elif "*" in hgvs_p:
            return "nonsense"
        elif "del" in hgvs_p:
            return "deletion"
        elif "dup" in hgvs_p:
            return "duplication"
        elif "ins" in hgvs_p:
            return "insertion"
        elif hgvs_p == "p.=":
            return "synonymous"
        elif re.match(r"p\.[A-Z][a-z]{2}\d+[A-Z][a-z]{2}", hgvs_p):
            return "missense"
        else:
            return "protein_other"
    
    if pd.notna(hgvs_c) and isinstance(hgvs_c, str):
        hgvs_c = hgvs_c.strip()
        if re.search(r"\+\d+|\-\d+", hgvs_c):
            if re.search(r"\+1\+2|\-1\-2", hgvs_c):
                return "splice_site_essential"
            else:
                return "splice_region"
        elif hgvs_c.startswith("c.-"):
            return "5'UTR"
        elif "*" in hgvs_c:
            return "3'UTR"
    
    return "unknown"



def filter_submission_by_variation_ids(submission_gz_path: str, variation_ids: List[str]) -> pd.DataFrame:
    """
    Î¦Î¹Î»Ï„ÏÎ¬ÏÎµÎ¹ Ï„Î¿ submission_summary.gz ÏÏƒÏ„Îµ Î½Î± ÎºÏÎ±Ï„Î®ÏƒÎµÎ¹ Î¼ÏŒÎ½Î¿ Ï„Î¹Ï‚ Î³ÏÎ±Î¼Î¼Î­Ï‚ Î¼Îµ Ï„Î± ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± VariationID.
    """
    temp_filename = "filtered_submission.tsv"
    
    # Î“ÏÎ¬Ï†Î¿Ï…Î¼Îµ Ï„Î¿ header
    with open(temp_filename, "w") as f_out:
        header_cmd = f"zcat {submission_gz_path} | head -n 1"
        subprocess.run(header_cmd, shell=True, stdout=f_out)

    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ regex pattern Î±Ï€ÏŒ ÏŒÎ»Î± Ï„Î± IDs (Ï€.Ï‡. 12345|67890|...)
    id_pattern = "|".join(map(str, variation_ids))
    
    # Î ÏÎ¿ÏƒÎ¸Î­Ï„Î¿Ï…Î¼Îµ Î³ÏÎ±Î¼Î¼Î­Ï‚ Î¼Îµ Î±Ï…Ï„Î¬ Ï„Î± IDs
    grep_cmd = f"zcat {submission_gz_path} | grep -E '{id_pattern}' >> {temp_filename}"
    subprocess.run(grep_cmd, shell=True, check=True)
    
    # Î¦Î¿ÏÏ„ÏÎ½Î¿Ï…Î¼Îµ ÏƒÎµ DataFrame
    df_submissions = pd.read_csv(temp_filename, sep='\t', low_memory=False)
    
    # Î”Î¹Î±Î³ÏÎ±Ï†Î® Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¿Ï Î±ÏÏ‡ÎµÎ¯Î¿Ï…
    os.remove(temp_filename)
    
    return df_submissions

  
def extract_submitters(submission_path: str, variation_ids: set) -> pd.DataFrame:
    """
    Î”Î¹Î±Î²Î¬Î¶ÎµÎ¹ Ï„Î¿ submission_summary ÏƒÎµ chunks ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î¼Î¿Î½Î±Î´Î¹ÎºÎ¿ÏÏ‚ Submitters Î±Î½Î¬ VariationID.
    """
    submitters = {}

   
    for chunk in pd.read_csv(submission_path, sep='\t', usecols=['VariationID', 'Submitter'], chunksize=500_000):
        filtered = chunk[chunk['VariationID'].isin(variation_ids)]
        for _, row in filtered.iterrows():
            vid = row['VariationID']
            sub = row['Submitter']
            if pd.notna(sub):
                submitters.setdefault(vid, set()).add(sub)

    # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ DataFrame
    df = pd.DataFrame([
        {'VariationID': vid, 'Submitter': sorted(list(subs))}
        for vid, subs in submitters.items()
    ])

    return df





def main():
    conn = psycopg2.connect(**DB_CONFIG)
    create_tables(conn)

    try:
        print("ÎÎµÎºÎ¯Î½Î·Î¼Î± script...")

        # ÎšÎ±Ï„Î­Î²Î±ÏƒÎ¼Î± Î±ÏÏ‡ÎµÎ¯Ï‰Î½
        variant_gz = "variant_summary.txt.gz"
        submission_gz = "submission_summary.txt.gz"
        urllib.request.urlretrieve(CLINVAR_VARIANT_URL, variant_gz)
        urllib.request.urlretrieve(CLINVAR_SUBMISSION_URL, submission_gz)

        # â¤ Î£Ï…Î³Ï‡ÏÎ½ÎµÏ…ÏƒÎ· variant + submission Î¼Îµ Î²Î¬ÏƒÎ· VariationID
        df_final = merge_variant_submission(variant_gz, submission_gz)

        # â¤ ACMG criteria + ÎµÏ€Î¹Ï€Î»Î­Î¿Î½ ÏƒÏ„Î®Î»ÎµÏ‚
        df_final['acmg_criteria'] = df_final.apply(apply_acmg_criteria, axis=1)
        df_final['conflicting_interpretations'] = [{} for _ in range(len(df_final))]
        df_final['rcv_accessions'] = df_final['RCVaccession'].fillna('').apply(
            lambda x: x.split('|') if x else []
        )

        # â¤ Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® ÏƒÏ„Î· Î²Î¬ÏƒÎ·
        insert_to_database(conn, df_final)

    except Exception as e:
        print(f"Î£Ï†Î¬Î»Î¼Î±: {e}")

    finally:
        # â¤ ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½ÏÎ½ Î±ÏÏ‡ÎµÎ¯Ï‰Î½
        for path in [variant_gz, submission_gz]:
            if os.path.exists(path):
                os.remove(path)
        conn.close()


if __name__ == "__main__":
    main()